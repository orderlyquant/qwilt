[
  {
    "objectID": "posts/2021-01-30-better-stock-correlation-analysis/better-stock-correlation-analysis.html",
    "href": "posts/2021-01-30-better-stock-correlation-analysis/better-stock-correlation-analysis.html",
    "title": "Better Stock Correlation Analysis",
    "section": "",
    "text": "Short-comings of previous analysis"
  },
  {
    "objectID": "posts/2021-01-30-better-stock-correlation-analysis/better-stock-correlation-analysis.html#api-consideration---repeated-pulls",
    "href": "posts/2021-01-30-better-stock-correlation-analysis/better-stock-correlation-analysis.html#api-consideration---repeated-pulls",
    "title": "Better Stock Correlation Analysis",
    "section": "API Consideration - repeated pulls",
    "text": "API Consideration - repeated pulls\nGetting to a completed post is an iterative process, that involves: work, knitting the document, assessing the current state, deciding what to add, then repeating until the final version. This leads to repetitive pulls of the data from Tiingo. So, I begin by executing a single pull and storing it, so that we avoid this repetition.\nRun this chunk once while working on the post, then set chunk options to eval=FALSE and echo=TRUE so that the code displays, but is not executed.\n\n# create S&P 500 constituent table\nsp500_tbl <- read_html(\n  \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n) %>%\n  html_element(\"#constituents\") %>%\n  html_table() %>%\n  janitor::clean_names()\n\nwrite_csv(sp500_tbl, \"data/sp500.csv\")\n\n# create AAPL peer pricing table\npeer_pricing_tbl <- sp500_tbl %>%\n  filter(\n    gics_sub_industry == sp500_tbl %>% filter(symbol == \"AAPL\") %>% pull(gics_sub_industry)\n  ) %>%\n  pull(symbol) %>%\n  tq_get(.x, get = \"tiingo\")\n\nwrite_csv(peer_pricing_tbl, \"data/peer_pricing.csv\")\n\nOnce this chunk has been run successfully, just load the data from the local csvs:sp500.csvandpeer_pricing.csv`.\n\nsp500_tbl <- read_csv(\"data/sp500.csv\")\npeer_pricing_tbl <- read_csv(\"data/peer_pricing.csv\")\n\nglimpse(sp500_tbl)\n\nRows: 505\nColumns: 9\n$ symbol                <chr> \"MMM\", \"ABT\", \"ABBV\", \"ABMD\", \"ACN\", \"ATVI\", \"AD…\n$ security              <chr> \"3M Company\", \"Abbott Laboratories\", \"AbbVie Inc…\n$ sec_filings           <chr> \"reports\", \"reports\", \"reports\", \"reports\", \"rep…\n$ gics_sector           <chr> \"Industrials\", \"Health Care\", \"Health Care\", \"He…\n$ gics_sub_industry     <chr> \"Industrial Conglomerates\", \"Health Care Equipme…\n$ headquarters_location <chr> \"St. Paul, Minnesota\", \"North Chicago, Illinois\"…\n$ date_first_added      <chr> \"1976-08-09\", \"1964-03-31\", \"2012-12-31\", \"2018-…\n$ cik                   <dbl> 66740, 1800, 1551152, 815094, 1467373, 718877, 7…\n$ founded               <chr> \"1902\", \"1888\", \"2013 (1888)\", \"1981\", \"1989\", \"…\n\nglimpse(peer_pricing_tbl)\n\nRows: 1,764\nColumns: 14\n$ symbol      <chr> \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"A…\n$ date        <dttm> 2020-01-31, 2020-02-03, 2020-02-04, 2020-02-05, 2020-02-0…\n$ open        <dbl> 320.93, 304.30, 315.31, 323.52, 322.57, 322.37, 314.18, 32…\n$ high        <dbl> 322.68, 313.49, 319.64, 324.76, 325.22, 323.40, 321.55, 32…\n$ low         <dbl> 308.29, 302.22, 313.63, 318.95, 320.26, 318.00, 313.85, 31…\n$ close       <dbl> 309.51, 308.66, 318.85, 321.45, 325.21, 320.03, 321.55, 31…\n$ volume      <dbl> 49897096, 43496401, 34154134, 29706718, 26356385, 29421012…\n$ adjusted    <dbl> 76.71393, 76.50326, 79.02891, 79.67334, 80.60527, 79.51223…\n$ adjHigh     <dbl> 79.97820, 77.70040, 79.22472, 80.49374, 80.60775, 80.34951…\n$ adjLow      <dbl> 76.41155, 74.90706, 77.73510, 79.05370, 79.37839, 79.00787…\n$ adjOpen     <dbl> 79.54445, 75.42260, 78.15150, 80.18640, 79.95093, 80.09361…\n$ adjVolume   <dbl> 199588384, 173985604, 136616536, 118826872, 105425540, 117…\n$ divCash     <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.77, 0.00, 0.00, 0.00, 0.00…\n$ splitFactor <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n\n# calculate returns as well\npeer_returns_tbl <- peer_pricing_tbl %>%\n  group_by(symbol) %>%\n  tq_transmute(adjusted, periodReturn, period = \"daily\", col_rename = \"return\")"
  },
  {
    "objectID": "posts/2021-01-30-better-stock-correlation-analysis/better-stock-correlation-analysis.html#fewer-steps-fewer-pairs",
    "href": "posts/2021-01-30-better-stock-correlation-analysis/better-stock-correlation-analysis.html#fewer-steps-fewer-pairs",
    "title": "Better Stock Correlation Analysis",
    "section": "Fewer steps, fewer pairs",
    "text": "Fewer steps, fewer pairs\nBuild a table with AAPL as symbol_1 and peer stocks as symbol_2, using the fact that left_join will create 1-row for every match of date. This is a succinct way of creating all return pairs.\n\naapl_peer_returns_tbl <-\n  peer_returns_tbl %>%\n    filter(symbol == \"AAPL\") %>%\n    select(symbol, date, return) %>%\n  left_join(\n    peer_returns_tbl %>%\n      filter(symbol != \"AAPL\") %>%\n      select(symbol, date, return),\n    by = \"date\",\n    suffix = c(\"_1\", \"_2\")\n  ) %>%\n  select(date, matches(\"symbol\"), everything()) %>%\n  arrange(symbol_2, date) %>%\n  filter(!(return_1 == 0 & return_2 == 0))  # remove days where returns == 0\n\nglimpse(aapl_peer_returns_tbl)\n\nRows: 1,506\nColumns: 5\n$ date     <dttm> 2020-02-03, 2020-02-04, 2020-02-05, 2020-02-06, 2020-02-07, …\n$ symbol_1 <chr> \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL…\n$ symbol_2 <chr> \"HPE\", \"HPE\", \"HPE\", \"HPE\", \"HPE\", \"HPE\", \"HPE\", \"HPE\", \"HPE\"…\n$ return_1 <dbl> -0.0027462764, 0.0330136720, 0.0081543045, 0.0116969980, -0.0…\n$ return_2 <dbl> 0.015075377, 0.019801980, 0.032593620, 0.002014775, -0.012064…\n\n\nNow, calculating correlations is simple via a single summarize call. Note: the use parameter of cor is left as the default “everything” which will cause NA to appear if there are any data issues. This is preferable to just returning a result, as we don’t have any data robustness built into the data pipeline.\n\naapl_peer_returns_tbl %>%\n  group_by(symbol_2) %>%\n  summarize(\n    cor = cor(return_1, return_2)\n  )\n\n# A tibble: 6 × 2\n  symbol_2   cor\n  <chr>    <dbl>\n1 HPE      0.477\n2 HPQ      0.498\n3 NTAP     0.537\n4 STX      0.548\n5 WDC      0.472\n6 XRX      0.460\n\n\nIt can be seen that we are getting the same results with less effort, e.g. no pivoting when comparing the above to the results shown below.\n\npeer_returns_tbl %>% \n  \n  # put returns into columns\n  pivot_wider(names_from = symbol, values_from = return) %>%\n  \n  # first day return is 0, so remove row\n  slice(-1) %>%\n  \n  # remove date column, so you can call `cor` on entire tibble\n  select(-date) %>%\n  \n  # calculate correlations\n  cor() %>%\n  \n  # `cor` returns a matrix, convert back into tibble\n  as_tibble(rownames = \"symbol_1\") %>%\n  \n  # transform into tidy format for easier processing\n  pivot_longer(-1, names_to = \"symbol_2\", values_to = \"cor\") %>%\n  \n  # remove the correlations of a stock with itself\n  filter(!(symbol_1 == symbol_2)) %>%\n  \n  # group by symbol_1 and arrange descending by correlation\n  group_by(symbol_1) %>%\n  arrange(desc(cor)) %>%\n  \n  # look at first row in each group == highest correlated stock\n  slice(1)\n\n# A tibble: 7 × 3\n# Groups:   symbol_1 [7]\n  symbol_1 symbol_2   cor\n  <chr>    <chr>    <dbl>\n1 AAPL     STX      0.548\n2 HPE      NTAP     0.712\n3 HPQ      XRX      0.781\n4 NTAP     HPE      0.712\n5 STX      WDC      0.705\n6 WDC      STX      0.705\n7 XRX      HPQ      0.781"
  },
  {
    "objectID": "posts/2021-01-30-better-stock-correlation-analysis/better-stock-correlation-analysis.html#correlation-evolution",
    "href": "posts/2021-01-30-better-stock-correlation-analysis/better-stock-correlation-analysis.html#correlation-evolution",
    "title": "Better Stock Correlation Analysis",
    "section": "Correlation evolution",
    "text": "Correlation evolution\nThe above analysis produces a single estimate of correlation using all of the data in the dataset. Since the purpose of calculating these correlations is to find a substitute security for a short time frame, 30 days, it is probably better to have a sense of how stable the relationship between the two stocks is through time.\nFor this, we will use the rollify function from the tibbletime package. Using the examples given in the documentation makes this relatively simple\n\nlibrary(tibbletime)\n\ncor_roll <- rollify(~cor(.x, .y), window = 30)\n\naapl_cor_tbl <-\n  aapl_peer_returns_tbl %>%\n  group_by(symbol_2) %>%\n  mutate(cor = cor_roll(return_1, return_2))\n\ntibbletime really is a great convenience.\nNotice how the correlations are noisy (expected), but have in general declined significantly (unexpected).\n\naapl_cor_tbl %>%\n  ggplot(aes(x = date, y = cor, color = symbol_2)) +\n  geom_hline(yintercept = 0, color = \"gray40\") +\n  geom_line() +\n  ylim(-1, 1) +\n  labs(\n    title = \"AAPL Stock Correlation\",\n    subtitle = \"with GICS sub-industry peers\",\n    caption = \"30-trading day rolling windows\",\n    x = NULL, y = NULL, color = NULL\n  ) +\n  theme_tq() +\n  scale_color_tq() +\n  # for legend to have 1 row\n  guides(col = guide_legend(nrow = 1))\n\n\n\n\nA smoothed version makes this trend a little clearer."
  },
  {
    "objectID": "posts/2021-01-28-harvesting-s5-500-sectors/post.html",
    "href": "posts/2021-01-28-harvesting-s5-500-sectors/post.html",
    "title": "Harvesting S&P 500 Sectors",
    "section": "",
    "text": "A little work with the rvest package. Try to get the current S&P 500 constituents from Wikipedia.\n\n\n\nAccording to my SelectorGadget work, the element I am looking for is “#constituents”\n\n\n{html_node}\n<table class=\"wikitable sortable\" id=\"constituents\">\n[1] <tbody>\\n<tr>\\n<th>\\n<a href=\"/wiki/Ticker_symbol\" title=\"Ticker symbol\"> ...\n\n\nSince this is a table, it needs to be passed through the html_table function.\n\n\n# A tibble: 503 × 9\n   symbol security        sec_f…¹ gics_…² gics_…³ headq…⁴ date_…⁵    cik founded\n   <chr>  <chr>           <chr>   <chr>   <chr>   <chr>   <chr>    <int> <chr>  \n 1 MMM    3M              reports Indust… Indust… Saint … 1976-0… 6.67e4 1902   \n 2 AOS    A. O. Smith     reports Indust… Buildi… Milwau… 2017-0… 9.11e4 1916   \n 3 ABT    Abbott          reports Health… Health… North … 1964-0… 1.8 e3 1888   \n 4 ABBV   AbbVie          reports Health… Pharma… North … 2012-1… 1.55e6 2013 (…\n 5 ABMD   Abiomed         reports Health… Health… Danver… 2018-0… 8.15e5 1981   \n 6 ACN    Accenture       reports Inform… IT Con… Dublin… 2011-0… 1.47e6 1989   \n 7 ATVI   Activision Bli… reports Commun… Intera… Santa … 2015-0… 7.19e5 2008   \n 8 ADM    ADM             reports Consum… Agricu… Chicag… 1981-0… 7.08e3 1902   \n 9 ADBE   Adobe Inc.      reports Inform… Applic… San Jo… 1997-0… 7.96e5 1982   \n10 ADP    ADP             reports Inform… Data P… Rosela… 1981-0… 8.67e3 1949   \n# … with 493 more rows, and abbreviated variable names ¹​sec_filings,\n#   ²​gics_sector, ³​gics_sub_industry, ⁴​headquarters_location, ⁵​date_first_added\n# ℹ Use `print(n = ...)` to see more rows\n\n\nWow! Sure enough, we get a tibble with what we want. Notice the use of janitor to clean up the column names for convenience. I think I should always do this.\nLet’s look at all of the stocks in the same gics_sub_industry as Apple.\n\n\n# A tibble: 6 × 4\n  symbol security                   gics_sector            gics_sub_industry    \n  <chr>  <chr>                      <chr>                  <chr>                \n1 AAPL   Apple Inc.                 Information Technology Technology Hardware,…\n2 HPE    Hewlett Packard Enterprise Information Technology Technology Hardware,…\n3 HPQ    HP Inc.                    Information Technology Technology Hardware,…\n4 NTAP   NetApp                     Information Technology Technology Hardware,…\n5 STX    Seagate Technology         Information Technology Technology Hardware,…\n6 WDC    Western Digital            Information Technology Technology Hardware,…\n\n\nThis is a great list to pass to tidyquant and try pulling some pricing data.\n\n\n\nBy default, we get about a years worth of prices. Let’s calculate returns:\n\n\n\nNow, calculate the correlation matrix:\n\n\n# A tibble: 6 × 3\n# Groups:   symbol_1 [6]\n  symbol_1 symbol_2   cor\n  <chr>    <chr>    <dbl>\n1 AAPL     NTAP     0.574\n2 HPE      HPQ      0.690\n3 HPQ      HPE      0.690\n4 NTAP     HPE      0.670\n5 STX      WDC      0.643\n6 WDC      STX      0.643"
  },
  {
    "objectID": "posts/2021-01-26_distill-and-timetk/post.html",
    "href": "posts/2021-01-26_distill-and-timetk/post.html",
    "title": "distill and timetk",
    "section": "",
    "text": "Today, I worked on the following:"
  },
  {
    "objectID": "posts/2021-01-26_distill-and-timetk/post.html#distill-blog",
    "href": "posts/2021-01-26_distill-and-timetk/post.html#distill-blog",
    "title": "distill and timetk",
    "section": "Distill blog",
    "text": "Distill blog\nSet up this blog using the distill package and github pages. A few takeaways:\n\nsee here for details on getting your repo right\nsee About for other details"
  },
  {
    "objectID": "posts/2021-01-26_distill-and-timetk/post.html#free-r-tip",
    "href": "posts/2021-01-26_distill-and-timetk/post.html#free-r-tip",
    "title": "distill and timetk",
    "section": "Free R Tip",
    "text": "Free R Tip\nThis week’s tip was about many ways to create data frames/tibbles. I was familiar with these, but found the use of timetk::tk_make_timeseries informative.\n\ntibble::tibble(\n  date          = timetk::tk_make_timeseries(\"2010\", length_out = 12, by = \"quarter\"),\n  interest_rate = (seq(12, 3, length.out = 12) * (sin(1:12) + 2)) / 12\n)\n\n# A tibble: 12 × 2\n   date       interest_rate\n   <date>             <dbl>\n 1 2010-01-01         2.84 \n 2 2010-04-01         2.71 \n 3 2010-07-01         1.85 \n 4 2010-10-01         0.989\n 5 2011-01-01         0.757\n 6 2011-04-01         1.13 \n 7 2011-07-01         1.57 \n 8 2011-10-01         1.56 \n 9 2012-01-01         1.10 \n10 2012-04-01         0.563\n11 2012-07-01         0.318\n12 2012-10-01         0.366\n\n\nNote that the by argument is very flexible:\n\nby - a character string, containing one of “sec”, “min”, “hour”, “day”, “week”, “month”, “quarter” or “year”. You can create regularly spaced sequences using phrases like by = “10 min”"
  },
  {
    "objectID": "posts/2021-01-26_distill-and-timetk/post.html#git-sql",
    "href": "posts/2021-01-26_distill-and-timetk/post.html#git-sql",
    "title": "distill and timetk",
    "section": "GIT + SQL",
    "text": "GIT + SQL\n\nYou will always need that query again, so “GIT” it\nQueries change through time, you may need a previous version when you realize the improved query “broke” something in a way that wasn’t immediately obvious\n\nsave with a .sql extension\n\n\nLooks like there are other interesting posts from this site. I added one to Notion, so it may be covered here someday."
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "Jan 30, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 28, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 26, 2021\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Orderly Qwilting",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nBetter Stock Correlation Analysis\n\n\n\n\n\n\n\ntidyquant\n\n\ntibbletime\n\n\nfinance\n\n\n\n\nBuilding on the previous post, with some considerations towards efficiency and increasing depth of analysis.\n\n\n\n\n\n\nJan 30, 2021\n\n\n4 min\n\n\n\n\n\n\n\n\nHarvesting S&P 500 Sectors\n\n\n\n\n\n\n\ntidyquant\n\n\nrvest\n\n\njanitor\n\n\nfinance\n\n\n\n\n“Using open source data to look at within industry correlations.”\n\n\n\n\n\n\nJan 28, 2021\n\n\n1 min\n\n\n\n\n\n\n\n\ndistill and timetk\n\n\n\n\n\n\n\ntimetk\n\n\ndistill\n\n\n\n\n“today’s directed wanderings”\n\n\n\n\n\n\nJan 26, 2021\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  }
]